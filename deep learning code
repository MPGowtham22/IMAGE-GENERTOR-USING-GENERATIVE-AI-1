pip install tensorflow keras
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU
from tensorflow.keras.optimizers import Adam

# Load MNIST dataset
(X_train, _), (_, _) = mnist.load_data()

# Preprocessing
X_train = X_train.astype('float32') / 255.0
X_train = np.expand_dims(X_train, axis=-1)

# Define generator model
def build_generator(latent_dim):
    generator = Sequential([
        Dense(7 * 7 * 128, input_dim=latent_dim),
        LeakyReLU(alpha=0.2),
        Reshape((7, 7, 128)),
        Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'),
        LeakyReLU(alpha=0.2),
        Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'),
        LeakyReLU(alpha=0.2),
        Conv2D(1, (7, 7), activation='sigmoid', padding='same')
    ])
    return generator

# Define discriminator model
def build_discriminator(input_shape):
    discriminator = Sequential([
        Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape),
        LeakyReLU(alpha=0.2),
        Conv2D(128, (3, 3), strides=(2, 2), padding='same'),
        LeakyReLU(alpha=0.2),
        Flatten(),
        Dense(1, activation='sigmoid')
    ])
    return discriminator

# Build GAN model
def build_gan(generator, discriminator):
    discriminator.trainable = False
    gan = Sequential([
        generator,
        discriminator
    ])
    return gan

# Compile models
latent_dim = 100
generator = build_generator(latent_dim)
discriminator = build_discriminator(X_train.shape[1:])
gan = build_gan(generator, discriminator)

discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))
gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))

# Training function
def train_gan(generator, discriminator, gan, X_train, latent_dim, epochs=100, batch_size=128):
    batch_count = X_train.shape[0] // batch_size
    for epoch in range(epochs):
        for batch in range(batch_count):
            # Generate random noise as input to the generator
            noise = np.random.normal(0, 1, (batch_size, latent_dim))
            # Generate fake images using the generator
            fake_images = generator.predict(noise)
            # Get a random batch of real images
            real_images = X_train[np.random.randint(0, X_train.shape[0], batch_size)]
            # Concatenate real and fake images into a batch for discriminator training
            X_batch = np.concatenate([real_images, fake_images])
            # Labels for real and fake images
            y_batch = np.zeros(2 * batch_size)
            y_batch[:batch_size] = 0.9  # One-sided label smoothing for real images
            # Train discriminator
            discriminator_loss = discriminator.train_on_batch(X_batch, y_batch)
            # Train generator (via the GAN model)
            noise = np.random.normal(0, 1, (batch_size, latent_dim))
            y_gan = np.ones(batch_size)
            generator_loss = gan.train_on_batch(noise, y_gan)
        # Print progress
        print(f'Epoch {epoch + 1}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}')
        # Save generated images
        if (epoch + 1) % 10 == 0:
            save_generated_images(generator, epoch + 1)

# Function to save generated images
def save_generated_images(generator, epoch, examples=10, latent_dim=100, save_dir='generated_images/'):
    noise = np.random.normal(0, 1, (examples, latent_dim))
    generated_images = generator.predict(noise)
    generated_images = generated_images * 255.0
    generated_images = generated_images.astype('uint8')
    plt.figure(figsize=(10, 10))
    for i in range(examples):
        plt.subplot(1, examples, i + 1)
        plt.imshow(generated_images[i, :, :, 0], cmap='gray')
        plt.axis('off')
    plt.tight_layout()
    plt.savefig(f'{save_dir}/generated_image_epoch_{epoch}.png')
    plt.close()

# Train GAN
train_gan(generator, discriminator, gan, X_train, latent_dim, epochs=100, batch_size=128)
